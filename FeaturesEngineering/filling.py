# -*- coding: utf-8 -*-
"""get_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D0Am-s4ekBuO6p9QJ7njNYQ_-3CFMLvV
"""

import pandas as pd
import numpy as np
import os
import sys
from google.colab import drive
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.impute import KNNImputer
from sklearn.preprocessing import MinMaxScaler
from clustering_methods import kmeans_clustering

drive.mount('/content/drive')
os.chdir('/content/drive/My Drive/QRT_FOOT_DATA_CHALLENGE')
from Utilities.data_process import scores_to_target

def fill_with_knn(train_data, train_scores, normalize = True, n_knn = 5):
  train_data_output = train_data.copy()
  train_data_processed = train_data.copy()
  if(normalize):
    scaler = MinMaxScaler()
    train_data_processed = scaler.fit_transform(train_data)
  imputer = KNNImputer(n_neighbors=n_knn)
  train_data_processed = imputer.fit_transform(train_data)
  train_target = scores_to_target(train_scores)
  if(normalize):
    train_data_processed = scaler.inverse_transform(train_data_processed)
  train_data_output[:] = train_data_processed
  return train_data_output, train_target

def fill_with_BayesianBridge(train_data, train_scores, normalize = True, max_iter = 100, tol = 0.01):
  train_data_output = train_data.copy()
  train_data_processed = train_data.copy()
  if(normalize):
    scaler = MinMaxScaler()
    train_data_processed = scaler.fit_transform(train_data_processed)
  imputer = IterativeImputer(max_iter=max_iter, tol=tol, verbose=1)
  train_data_processed = imputer.fit_transform(train_data_processed)
  if(normalize):
    train_data_processed = scaler.inverse_transform(train_data_processed)
  train_target = scores_to_target(train_scores)
  train_data_output[:] = train_data_processed
  return train_data_output, train_target
  
def fill_with_median(train_data, train_scores):
  train_data = train_data.fillna(train_data.median())
  train_target = scores_to_target(train_scores)
  return train_data, train_target
  
def fill_with_mean(train_data, train_scores):
  train_data = train_data.fillna(train_data.mean())
  train_target = scores_to_target(train_scores)
  return train_data, train_target
  
def fill_with_kmeans(train_data, train_scores, n_clusters = 4, is_median = True, normalize = True):
  train_data_output = train_data.copy()
  train_data_processed = train_data.copy()
  train_data_processed = kmeans_clustering(train_data_processed, n_clusters, normalize = normalize).copy()
  if(is_median):
    for label in train_data_processed['cluster'].unique():
      train_data_processed.loc[train_data_processed['cluster'] == label] = train_data_processed.loc[train_data_processed['cluster'] == label].fillna(train_data_processed.loc[train_data_processed['cluster'] == label].median())
  else:
    for label in train_data_processed['cluster'].unique():
      train_data_processed.loc[train_data_processed['cluster'] == label] = train_data_processed.loc[train_data_processed['cluster'] == label].fillna(train_data_processed.loc[train_data_processed['cluster'] == label].mean())
  train_target = scores_to_target(train_scores)
  train_data_output[:] = train_data_processed
  return train_data_output, train_target
  
def drop_missing_values(train_data, train_scores):
  train_data = train_data.loc[(train_data.isna().sum(axis=1) == 0)].copy()
  train_scores = train_scores.loc[train_data.index].copy()
  train_target = scores_to_target(train_scores)
  return train_data, train_target

def fill_with_xgb(df: pd.DataFrame, max_depth = 3, learning_rate = 0.1, n_estimators = 100, subsample = 1.0, colsample_bytree = 1.0, random_state = 42):
    dataframe = df.copy()
    for col in dataframe.columns:
        nan_idx = np.where(dataframe[col].isna())[0]
        dataframe['NaN_values'] = 0
        dataframe.loc[nan_idx, 'NaN_values'] = 1
        df_train = dataframe[dataframe['NaN_values'] == 0]
        df_test = dataframe[dataframe['NaN_values'] == 1]
        X_train = df_train.drop([col, 'NaN_values'], axis=1)
        y_train = df_train[col]
        X_test = df_test.drop([col, 'NaN_values'], axis=1)
        model_xgb = xgb.XGBRegressor(random_state=random_state, n_estimators = n_estimators, max_depth = max_depth, learning_rate = learning_rate, subsample = subsample, colsample_bytree = colsample_bytree)
        model_xgb.fit(X_train, y_train)
        y_pred = model_xgb.predict(X_test)
        df.loc[nan_idx, col] = y_pred
    return df