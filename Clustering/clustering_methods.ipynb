{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOR8uCQLOnzfQkLvQLMQe7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"AJg0Aqc3Yu1N","executionInfo":{"status":"ok","timestamp":1729441173581,"user_tz":-120,"elapsed":388,"user":{"displayName":"Rene Coty","userId":"12594185769810915282"}}},"outputs":[],"source":["from sklearn.cluster import KMeans\n","from sklearn.preprocessing import MinMaxScaler\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["def kmeans_clustering(train_data, n_clusters = 4, fill_init_median = True, normalize = True):\n","  if(fill_init_median):\n","    train_data_copy = train_data.fillna(train_data.median()).copy()\n","  else:\n","    train_data_copy = train_data.fillna(train_data.mean()).copy()\n","  if(normalize):\n","    scaler = MinMaxScaler()\n","    train_data_copy = scaler.fit_transform(train_data_copy)\n","  kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(train_data_copy)\n","  train_data['cluster'] = kmeans.labels_\n","  return train_data"],"metadata":{"id":"xVdZncJGaqP8","executionInfo":{"status":"ok","timestamp":1729441212378,"user_tz":-120,"elapsed":383,"user":{"displayName":"Rene Coty","userId":"12594185769810915282"}}},"execution_count":3,"outputs":[]}]}